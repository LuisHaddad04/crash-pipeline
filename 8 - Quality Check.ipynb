{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "136c1228",
   "metadata": {},
   "source": [
    "\n",
    "# **ðŸ§ª Quality Check (QC)**\n",
    "\n",
    "Validates **Crash_type (binary or multi-class)**, **Hit and Run**, and **Fatality Risk**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c8f5a",
   "metadata": {},
   "source": [
    "## **0) (Optional) Install pandas/numpy (usually preinstalled)**\n",
    "\n",
    "Installs any missing Python packages so the notebook runs consistently on fresh environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "179842f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: duckdb in /opt/anaconda3/lib/python3.13/site-packages (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy\n",
    "!pip install duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e56b46",
   "metadata": {},
   "source": [
    "## **1) Configure outcome and thresholds**\n",
    "\n",
    "To know your DB, schema, table name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cffc282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  database_name schema_name table_name\n",
      "0          gold  crash_gold    crashes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import duckdb\n",
    "con = duckdb.connect()\n",
    "con.execute(\"ATTACH 'gold.duckdb' AS gold (READ_ONLY)\")\n",
    "\n",
    "# === Show all tables (DB, schema, table name) ===\n",
    "result = con.execute(\"\"\"\n",
    "  SELECT database_name, schema_name, table_name\n",
    "  FROM duckdb_tables()\n",
    "  WHERE database_name = 'gold'\n",
    "  ORDER BY 1,2,3\n",
    "\"\"\").df()\n",
    "\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b4dd2a",
   "metadata": {},
   "source": [
    "Using the above details update the TABLE_BY_OUTCOME variable \n",
    "\n",
    "Sets the OUTCOME, connects table names to DuckDB, chooses the target column, and defines QC thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fb6dc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome = Crash_type  |  Target column = crash_type\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3708c6cf14f9451fa131f7dbf3a8f78d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded gold\".\"crash_gold\".\"crashes with shape: (943744, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash_record_id</th>\n",
       "      <th>crash_date</th>\n",
       "      <th>crash_type</th>\n",
       "      <th>weather_condition</th>\n",
       "      <th>lighting_condition</th>\n",
       "      <th>prim_contributory_cause</th>\n",
       "      <th>traffic_control_device</th>\n",
       "      <th>roadway_surface_cond</th>\n",
       "      <th>sec_contributory_cause</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>hour_bin</th>\n",
       "      <th>work_zone_i</th>\n",
       "      <th>hit_and_run_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b447da7df1755533a29dda2ec074d3c80fb359f4e10ed4...</td>\n",
       "      <td>2022-10-26 09:43:00</td>\n",
       "      <td>0</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>UNABLE TO DETERMINE</td>\n",
       "      <td>NO CONTROLS</td>\n",
       "      <td>DRY</td>\n",
       "      <td>UNABLE TO DETERMINE</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53f6d0352ffc67413d6d41e076632b8c066cc71a746d7a...</td>\n",
       "      <td>2022-10-26 08:09:00</td>\n",
       "      <td>0</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DRIVING SKILLS/KNOWLEDGE/EXPERIENCE</td>\n",
       "      <td>TRAFFIC SIGNAL</td>\n",
       "      <td>DRY</td>\n",
       "      <td>DRIVING SKILLS/KNOWLEDGE/EXPERIENCE</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27508d0ba098696edac05b898a9648e9b8dc6dacd41006...</td>\n",
       "      <td>2022-10-26 02:22:00</td>\n",
       "      <td>1</td>\n",
       "      <td>RAIN</td>\n",
       "      <td>DARKNESS, LIGHTED ROAD</td>\n",
       "      <td>DRIVING ON WRONG SIDE/WRONG WAY</td>\n",
       "      <td>NO CONTROLS</td>\n",
       "      <td>WET</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b6c2dfca15dbea1ea24164ae19d29506f36dcc4cf00f01...</td>\n",
       "      <td>2022-10-25 20:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>RAIN</td>\n",
       "      <td>DARKNESS, LIGHTED ROAD</td>\n",
       "      <td>UNABLE TO DETERMINE</td>\n",
       "      <td>NO CONTROLS</td>\n",
       "      <td>WET</td>\n",
       "      <td>UNABLE TO DETERMINE</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>evening</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4b6c0a199f9808d4ad71e0b7b6872803bd3d8b5a4cf160...</td>\n",
       "      <td>2022-10-25 18:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>RAIN</td>\n",
       "      <td>DARKNESS, LIGHTED ROAD</td>\n",
       "      <td>FOLLOWING TOO CLOSELY</td>\n",
       "      <td>TRAFFIC SIGNAL</td>\n",
       "      <td>WET</td>\n",
       "      <td>WEATHER</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c0add7f137cb0556b773c6c515fa68d51c4ca298196cf5...</td>\n",
       "      <td>2022-10-25 15:43:00</td>\n",
       "      <td>0</td>\n",
       "      <td>RAIN</td>\n",
       "      <td>DARKNESS</td>\n",
       "      <td>NOT APPLICABLE</td>\n",
       "      <td>NO CONTROLS</td>\n",
       "      <td>WET</td>\n",
       "      <td>NOT APPLICABLE</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2c1d2985fa2eb87ab3d8014c83a01bcccf759cad43bbe4...</td>\n",
       "      <td>2022-10-25 14:25:00</td>\n",
       "      <td>1</td>\n",
       "      <td>RAIN</td>\n",
       "      <td>DUSK</td>\n",
       "      <td>FAILING TO YIELD RIGHT-OF-WAY</td>\n",
       "      <td>None</td>\n",
       "      <td>WET</td>\n",
       "      <td>NOT APPLICABLE</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b5fcc1196ce3b070ddc5dbf73c74f8dda549b5df6ee371...</td>\n",
       "      <td>2022-10-25 10:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>RAIN</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>FAILING TO REDUCE SPEED TO AVOID CRASH</td>\n",
       "      <td>TRAFFIC SIGNAL</td>\n",
       "      <td>WET</td>\n",
       "      <td>NOT APPLICABLE</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6997197f1f385ae6189b07889b603dad22fb37e441b078...</td>\n",
       "      <td>2022-10-25 08:55:00</td>\n",
       "      <td>0</td>\n",
       "      <td>RAIN</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>UNABLE TO DETERMINE</td>\n",
       "      <td>NO CONTROLS</td>\n",
       "      <td>WET</td>\n",
       "      <td>UNABLE TO DETERMINE</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>83219f837c49d6e2937ac6075bcaf2d3da74e8d0279c3e...</td>\n",
       "      <td>2022-10-25 08:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>RAIN</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>UNABLE TO DETERMINE</td>\n",
       "      <td>NO CONTROLS</td>\n",
       "      <td>WET</td>\n",
       "      <td>NOT APPLICABLE</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     crash_record_id          crash_date  \\\n",
       "0  b447da7df1755533a29dda2ec074d3c80fb359f4e10ed4... 2022-10-26 09:43:00   \n",
       "1  53f6d0352ffc67413d6d41e076632b8c066cc71a746d7a... 2022-10-26 08:09:00   \n",
       "2  27508d0ba098696edac05b898a9648e9b8dc6dacd41006... 2022-10-26 02:22:00   \n",
       "3  b6c2dfca15dbea1ea24164ae19d29506f36dcc4cf00f01... 2022-10-25 20:00:00   \n",
       "4  4b6c0a199f9808d4ad71e0b7b6872803bd3d8b5a4cf160... 2022-10-25 18:30:00   \n",
       "5  c0add7f137cb0556b773c6c515fa68d51c4ca298196cf5... 2022-10-25 15:43:00   \n",
       "6  2c1d2985fa2eb87ab3d8014c83a01bcccf759cad43bbe4... 2022-10-25 14:25:00   \n",
       "7  b5fcc1196ce3b070ddc5dbf73c74f8dda549b5df6ee371... 2022-10-25 10:45:00   \n",
       "8  6997197f1f385ae6189b07889b603dad22fb37e441b078... 2022-10-25 08:55:00   \n",
       "9  83219f837c49d6e2937ac6075bcaf2d3da74e8d0279c3e... 2022-10-25 08:30:00   \n",
       "\n",
       "   crash_type weather_condition      lighting_condition  \\\n",
       "0           0             CLEAR                DAYLIGHT   \n",
       "1           0             CLEAR                DAYLIGHT   \n",
       "2           1              RAIN  DARKNESS, LIGHTED ROAD   \n",
       "3           0              RAIN  DARKNESS, LIGHTED ROAD   \n",
       "4           0              RAIN  DARKNESS, LIGHTED ROAD   \n",
       "5           0              RAIN                DARKNESS   \n",
       "6           1              RAIN                    DUSK   \n",
       "7           0              RAIN                DAYLIGHT   \n",
       "8           0              RAIN                DAYLIGHT   \n",
       "9           0              RAIN                DAYLIGHT   \n",
       "\n",
       "                  prim_contributory_cause traffic_control_device  \\\n",
       "0                     UNABLE TO DETERMINE            NO CONTROLS   \n",
       "1     DRIVING SKILLS/KNOWLEDGE/EXPERIENCE         TRAFFIC SIGNAL   \n",
       "2         DRIVING ON WRONG SIDE/WRONG WAY            NO CONTROLS   \n",
       "3                     UNABLE TO DETERMINE            NO CONTROLS   \n",
       "4                   FOLLOWING TOO CLOSELY         TRAFFIC SIGNAL   \n",
       "5                          NOT APPLICABLE            NO CONTROLS   \n",
       "6           FAILING TO YIELD RIGHT-OF-WAY                   None   \n",
       "7  FAILING TO REDUCE SPEED TO AVOID CRASH         TRAFFIC SIGNAL   \n",
       "8                     UNABLE TO DETERMINE            NO CONTROLS   \n",
       "9                     UNABLE TO DETERMINE            NO CONTROLS   \n",
       "\n",
       "  roadway_surface_cond               sec_contributory_cause  year  month  day  \\\n",
       "0                  DRY                  UNABLE TO DETERMINE  2022     10   26   \n",
       "1                  DRY  DRIVING SKILLS/KNOWLEDGE/EXPERIENCE  2022     10   26   \n",
       "2                  WET                              WEATHER  2022     10   26   \n",
       "3                  WET                  UNABLE TO DETERMINE  2022     10   25   \n",
       "4                  WET                              WEATHER  2022     10   25   \n",
       "5                  WET                       NOT APPLICABLE  2022     10   25   \n",
       "6                  WET                       NOT APPLICABLE  2022     10   25   \n",
       "7                  WET                       NOT APPLICABLE  2022     10   25   \n",
       "8                  WET                  UNABLE TO DETERMINE  2022     10   25   \n",
       "9                  WET                       NOT APPLICABLE  2022     10   25   \n",
       "\n",
       "   hour day_of_week  is_weekend   hour_bin  work_zone_i  hit_and_run_i  \n",
       "0     9   Wednesday           0    morning            0              0  \n",
       "1     8   Wednesday           0    morning            0              0  \n",
       "2     2   Wednesday           0      night            0              0  \n",
       "3    20     Tuesday           0    evening            0              1  \n",
       "4    18     Tuesday           0  afternoon            0              1  \n",
       "5    15     Tuesday           0  afternoon            0              0  \n",
       "6    14     Tuesday           0  afternoon            0              0  \n",
       "7    10     Tuesday           0    morning            0              0  \n",
       "8     8     Tuesday           0    morning            0              0  \n",
       "9     8     Tuesday           0    morning            0              1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import os, re, math\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Config ---\n",
    "OUTCOME = \"Crash_type\"  # or: \"Crash_type\", \"Hit and Run\", \"Fatality Risk\"\n",
    "DB_PATH = \"gold.duckdb\"\n",
    "TABLE_BY_OUTCOME = {\n",
    "    \"Crash_type\": 'gold\".\"crash_gold\".\"crashes',        # db.schema.Table_name â†’ gold.duckdb.gold.gold_crash_type\n",
    "    \"Hit and Run\": 'gold\".\"gold\".\"crashes',               # db.schema.Table_name â†’ gold.duckdb.gold.crashes \n",
    "    \"Fatality Risk\": 'gold\".\"gold\".\"gold_fatality_risk',  # db.schema.Table_name â†’ gold.duckdb.gold.gold_fatality_risk\n",
    "}\n",
    "\n",
    "\n",
    "TABLE_NAME = TABLE_BY_OUTCOME[OUTCOME]\n",
    "\n",
    "# --- Columns and Targets ---\n",
    "DEFAULT_TARGET_BY_OUTCOME = {\n",
    "    \"Crash_type\": \"crash_type\",\n",
    "    \"Hit and Run\": \"hit_and_run_i\",\n",
    "    \"Fatality Risk\": \"fatality_risk\"\n",
    "}\n",
    "TARGET_COL = None\n",
    "ID_COL = \"crash_record_id\"\n",
    "DATE_COL = \"crash_date\"\n",
    "\n",
    "# --- Leakage Hints & Thresholds ---\n",
    "LEAKAGE_HINTS = {\n",
    "    \"Hit and Run\": [\"hit_and_run\", \"hit-run\", \"hitrun\"],\n",
    "    \"Fatality Risk\": [\"injuries_fatal\", \"injuries_total\", \"injuries_incapacitating\"],\n",
    "    \"Crash_type\": [\"crash_type\"]\n",
    "}\n",
    "# QC thresholds (tune for your dataset size & tolerance)\n",
    "MISSING_WARN = 0.20   # warn if a column's missing-rate > 20%.\n",
    "                      # Typical: 0.10 (strict) to 0.30 (lenient). Use ~0.20 for general QC.\n",
    "\n",
    "HIGH_CARD_LIMIT = 100 # flag categorical columns with >100 unique values as \"high-cardinality\".\n",
    "                      # Typical: 50â€“200. Lower for small datasets; higher if you expect many IDs/buckets.\n",
    "\n",
    "OUTLIER_RATE_WARN = 0.02  # warn if an individual numeric column has >2% outliers by IQR rule.\n",
    "                          # Typical: 0.01 (strict) to 0.05 (lenient). Use ~0.02 for balanced sensitivity.\n",
    "\n",
    "\n",
    "# --- Derived Vars ---\n",
    "TARGET = (TARGET_COL or DEFAULT_TARGET_BY_OUTCOME.get(OUTCOME))\n",
    "assert OUTCOME in DEFAULT_TARGET_BY_OUTCOME, f\"Unsupported OUTCOME: {OUTCOME}\"\n",
    "print(f\"Outcome = {OUTCOME}  |  Target column = {TARGET}\")\n",
    "\n",
    "# --- Load data from DuckDB ---\n",
    "with duckdb.connect(DB_PATH, read_only=True) as con:\n",
    "    df = con.execute(f'SELECT * FROM \"{TABLE_NAME}\"').df()\n",
    "\n",
    "print(f\"Loaded {TABLE_NAME} with shape: {df.shape}\")\n",
    "\n",
    "# --- Date conversion ---\n",
    "if DATE_COL in df.columns:\n",
    "    df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"coerce\")\n",
    "\n",
    "# --- Display sample ---\n",
    "display(df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76da5a9d",
   "metadata": {},
   "source": [
    "## **2) Schema & primary key checks**\n",
    "\n",
    "Confirms required columns exist and verifies crash_record_id is non-null and unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f65b9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "issues = issues if 'issues' in globals() else []\n",
    "\n",
    "REQUIRED_COLUMNS = [\n",
    "    'crash_record_id', 'weather_condition','lighting_condition'\n",
    "]\n",
    "\n",
    "missing_required = [c for c in REQUIRED_COLUMNS if c not in df.columns]\n",
    "if missing_required:\n",
    "    issues.append((\"SCHEMA\", f\"Missing required columns: {missing_required}\"))\n",
    "    print(\"[SCHEMA] Missing:\", missing_required)\n",
    "\n",
    "if 'crash_record_id' not in df.columns:\n",
    "    issues.append((\"KEY\", \"crash_record_id column missing\"))\n",
    "else:\n",
    "    null_ids = df['crash_record_id'].isna().sum()\n",
    "    if null_ids > 0:\n",
    "        issues.append((\"KEY\", f\"{null_ids} rows have NULL crash_record_id\"))\n",
    "        print(\"[KEY] NULL crash_record_id rows:\", null_ids)\n",
    "    nunique_ids = df['crash_record_id'].nunique(dropna=True)\n",
    "    if nunique_ids != len(df):\n",
    "        approx_dupes = int(len(df) - nunique_ids)\n",
    "        issues.append((\"KEY\", f\"crash_record_id not unique (duplicates ~ {approx_dupes})\"))\n",
    "        print(\"[KEY] Non-unique crash_record_id; ~dupes:\", approx_dupes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03b216a",
   "metadata": {},
   "source": [
    "## **3) QC readiness (no cleaning)**\n",
    "\n",
    "Validates basic dataframe readiness for QC (consistent names/types, safe coercions) â€” does not perform cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e037f227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target present? True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.columns = [re.sub(r\"\\s+\", \"_\", c.strip().lower()) for c in df.columns]\n",
    "ID = ID_COL.lower() if ID_COL else None\n",
    "DATE = DATE_COL.lower() if DATE_COL else None\n",
    "TARGET = TARGET.lower() if TARGET else None\n",
    "print(\"Target present?\", TARGET in df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136efa3b",
   "metadata": {},
   "source": [
    "## **4) Duplicates**\n",
    "\n",
    "Checks dataset grain and flags duplicate records or non-unique keys for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dee67b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "issues = []\n",
    "if ID in df.columns:\n",
    "    dup_ids = df[ID].value_counts()\n",
    "    dup_ids = dup_ids[dup_ids > 1]\n",
    "    if not dup_ids.empty:\n",
    "        issues.append((\"DUPLICATES\", f\"{dup_ids.shape[0]} duplicated {ID} values\"))\n",
    "        display(dup_ids.head(10).to_frame(\"count\"))\n",
    "else:\n",
    "    before = df.shape[0]\n",
    "    after = df.drop_duplicates().shape[0]\n",
    "    if before - after > 0:\n",
    "        issues.append((\"DUPLICATES\", f\"{before - after} fully-duplicate rows\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6318acfd",
   "metadata": {},
   "source": [
    "## **5) Missingness**\n",
    "\n",
    "Computes per-column missing rates and highlights columns exceeding the warning threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae287728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>roadway_surface_cond</td>\n",
       "      <td>0.058540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>traffic_control_device</td>\n",
       "      <td>0.038765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weather_condition</td>\n",
       "      <td>0.020849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lighting_condition</td>\n",
       "      <td>0.013682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crash_date</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crash_record_id</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>prim_contributory_cause</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crash_type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sec_contributory_cause</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>year</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>month</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>day</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hour</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>day_of_week</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is_weekend</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hour_bin</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>work_zone_i</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hit_and_run_i</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     column  missing_rate\n",
       "7      roadway_surface_cond      0.058540\n",
       "6    traffic_control_device      0.038765\n",
       "3         weather_condition      0.020849\n",
       "4        lighting_condition      0.013682\n",
       "1                crash_date      0.000000\n",
       "0           crash_record_id      0.000000\n",
       "5   prim_contributory_cause      0.000000\n",
       "2                crash_type      0.000000\n",
       "8    sec_contributory_cause      0.000000\n",
       "9                      year      0.000000\n",
       "10                    month      0.000000\n",
       "11                      day      0.000000\n",
       "12                     hour      0.000000\n",
       "13              day_of_week      0.000000\n",
       "14               is_weekend      0.000000\n",
       "15                 hour_bin      0.000000\n",
       "16              work_zone_i      0.000000\n",
       "17            hit_and_run_i      0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "miss = (df.isna().mean().rename(\"missing_rate\").reset_index()\n",
    "          .rename(columns={\"index\":\"column\"})\n",
    "          .sort_values(\"missing_rate\", ascending=False))\n",
    "display(miss.head(20))\n",
    "if (miss[\"missing_rate\"] > MISSING_WARN).any():\n",
    "    issues.append((\"MISSINGNESS\", \"Some columns exceed missingness threshold\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409955b6",
   "metadata": {},
   "source": [
    "## **6) Target checks** \n",
    "\n",
    "Profiles the target: coerces to binary/ordinal when applicable and stores distribution metadata for reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d6f117e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Target `crash_type` (k=2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crash_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>680584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count\n",
       "crash_type        \n",
       "0           680584\n",
       "1           263160"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class balance (binary):\n",
      "- total=943744, pos=263160, neg=680584\n",
      "- minority_rate=0.279, imbalance_ratio=2.59\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import Optional, Tuple, Dict\n",
    "\n",
    "# Canonicalize OUTCOME names so students can use small variants\n",
    "_OUTCOME_ALIASES = {\n",
    "    \"crash_type\": \"Crash_type\",\n",
    "    \"crash type\": \"Crash_type\",\n",
    "    \"hit&run\": \"Hit and Run\",\n",
    "    \"hit & run\": \"Hit and Run\",\n",
    "    \"fatality_risk\": \"Fatality Risk\",\n",
    "    \"fatality  risk\": \"Fatality Risk\",\n",
    "}\n",
    "_outcome_key = OUTCOME.strip()\n",
    "_outcome_key = _OUTCOME_ALIASES.get(_outcome_key.lower(), _outcome_key)\n",
    "\n",
    "# Enforce allowed outcomes only\n",
    "_ALLOWED = {\"Crash_type\", \"Hit and Run\", \"Fatality Risk\"}\n",
    "if _outcome_key not in _ALLOWED:\n",
    "    raise ValueError(f\"Unsupported OUTCOME: {OUTCOME}. Allowed: {sorted(_ALLOWED)}\")\n",
    "OUTCOME = _outcome_key  # overwrite with canonical value\n",
    "\n",
    "# --- Helpers (generic) ---\n",
    "def _normalize_binary_series_generic(s: pd.Series) -> Tuple[pd.Series, Optional[Dict[str,int]]]:\n",
    "    \"\"\"\n",
    "    Coerce common binary encodings to {0,1}. (No KSI terms here.)\n",
    "    \"\"\"\n",
    "    if s is None:\n",
    "        return s, None\n",
    "    uniq_raw = set(pd.Series(s.dropna().unique()).tolist())\n",
    "    if uniq_raw <= {0,1}:\n",
    "        return s.astype(\"Int64\"), None\n",
    "\n",
    "    sv = s.astype(str).str.strip().str.lower()\n",
    "    mapping = {\n",
    "        \"1\": 1, \"0\": 0,\n",
    "        \"true\": 1, \"false\": 0,\n",
    "        \"y\": 1, \"n\": 0,\n",
    "        \"yes\": 1, \"no\": 0,\n",
    "    }\n",
    "    mapped = sv.map(mapping)\n",
    "    if mapped.dropna().isin([0,1]).all() and mapped.notna().any():\n",
    "        return mapped.astype(\"Int64\"), mapping\n",
    "    return s, None\n",
    "\n",
    "def _try_map_fatality_ordinal(s: pd.Series) -> Tuple[Optional[pd.Series], Optional[Dict[str,int]]]:\n",
    "    \"\"\"\n",
    "    Map common severity terms to an ordered 0..K-1 scale for Fatality Risk if present.\n",
    "    \"\"\"\n",
    "    sv = s.astype(str).str.strip().str.lower()\n",
    "    # If small numeric scale (0..5 etc.), just coerce\n",
    "    num_try = pd.to_numeric(sv, errors=\"coerce\")\n",
    "    uniq = sorted(num_try.dropna().unique())\n",
    "    if 2 < len(uniq) <= 8 and (pd.Series(uniq).max() <= 10):\n",
    "        return num_try.astype(\"Int64\"), {\"numeric_scale_detected\": True}\n",
    "    # Text buckets (customize as needed)\n",
    "    lut = {\n",
    "        \"none\": 0, \"no injury\": 0, \"no fatality\": 0,\n",
    "        \"low\": 1, \"minor\": 1,\n",
    "        \"medium\": 2, \"moderate\": 2, \"med\": 2,\n",
    "        \"high\": 3, \"serious\": 3, \"severe\": 3,\n",
    "        \"fatal\": 4, \"death\": 4\n",
    "    }\n",
    "    mapped = sv.map(lut)\n",
    "    if mapped.notna().any():\n",
    "        return mapped.astype(\"Int64\"), lut\n",
    "    return None, None\n",
    "\n",
    "# --- Target analysis starts here ---\n",
    "target_info = {}\n",
    "if TARGET and TARGET in df.columns:\n",
    "    col = TARGET\n",
    "    nonnull = df[col].dropna()\n",
    "    uniq_vals = sorted(pd.Series(nonnull.unique()).tolist(), key=lambda x: str(x))\n",
    "    k = len(uniq_vals)\n",
    "\n",
    "    target_info = {\n",
    "        \"name\": col,\n",
    "        \"k\": k,\n",
    "        \"values\": uniq_vals[:12]\n",
    "    }\n",
    "\n",
    "    expects_binary = False\n",
    "    if OUTCOME == \"Hit and Run\":\n",
    "        expects_binary = True\n",
    "    elif OUTCOME == \"Crash_type\":\n",
    "        # Crash_type can be binary (2 string labels) or multiclass\n",
    "        expects_binary = (k == 2)\n",
    "        if k > 30:\n",
    "            issues.append((\"TARGET\", f\"{k} categories â€” consider grouping rare levels for Crash_type\"))\n",
    "    elif OUTCOME == \"Fatality Risk\":\n",
    "        # Typically binary (KSI vs Non-KSI) or ordinal severity; try binary if k==2, else try ordinal\n",
    "        expects_binary = (k == 2)\n",
    "\n",
    "    series_for_balance = None\n",
    "\n",
    "    # ----- Outcome-specific handling -----\n",
    "    if OUTCOME == \"Fatality Risk\" and k > 2:\n",
    "        # Try ordinal mapping first\n",
    "        ord_series, ord_map = _try_map_fatality_ordinal(df[col])\n",
    "        if ord_series is not None:\n",
    "            ord_col = col + \"_ord\"\n",
    "            df[ord_col] = ord_series\n",
    "            target_info[\"ordinal_column\"] = ord_col\n",
    "            target_info[\"interpreted_as\"] = \"ordinal\"\n",
    "            target_info[\"ordinal_mapping\"] = ord_map\n",
    "        else:\n",
    "            # Try binary mapping using common KSI strings (scoped here only)\n",
    "            sv = df[col].astype(str).str.strip().str.lower()\n",
    "            ksi_map = {\n",
    "                \"ksi\": 1, \"k.s.i\": 1,\n",
    "                \"non-ksi\": 0, \"non ksi\": 0, \"non_ksi\": 0, \"non ksi \": 0\n",
    "            }\n",
    "            mapped = sv.map(ksi_map)\n",
    "            if mapped.dropna().isin([0,1]).all() and mapped.notna().any():\n",
    "                bin_col = col + \"_bin\"\n",
    "                df[bin_col] = mapped.astype(\"Int64\")\n",
    "                target_info[\"binary_column\"] = bin_col\n",
    "                target_info[\"interpreted_as\"] = \"binary\"\n",
    "                issues.append((\"TARGET\", f\"Normalized `{col}` to {{0,1}} using KSI mapping â†’ `{bin_col}`\"))\n",
    "                series_for_balance = df[bin_col]\n",
    "            else:\n",
    "                issues.append((\"TARGET\", f\"`{col}` has {k} distinct values â€” expected binary/ordinal for Fatality Risk\"))\n",
    "\n",
    "    # Binary normalization for outcomes that should be binary\n",
    "    if expects_binary and series_for_balance is None:\n",
    "        s_norm, used_map = _normalize_binary_series_generic(df[col])\n",
    "        uniq_after = set(pd.Series(s_norm.dropna().unique()).tolist())\n",
    "        if uniq_after <= {0,1}:\n",
    "            bin_col = col + \"_bin\"\n",
    "            df[bin_col] = s_norm\n",
    "            target_info[\"binary_column\"] = bin_col\n",
    "            target_info[\"interpreted_as\"] = \"binary\"\n",
    "            if used_map:\n",
    "                issues.append((\"TARGET\", f\"Normalized `{col}` to {{0,1}} using mapping {used_map} â†’ `{bin_col}`\"))\n",
    "            series_for_balance = df[bin_col]\n",
    "        else:\n",
    "            if k == 2:\n",
    "                issues.append((\"TARGET\", f\"`{col}` is binary but uses non 0/1 encodings: {uniq_vals}\"))\n",
    "            else:\n",
    "                # For Crash_type multiclass, we accept; for Fatality Risk we warned above.\n",
    "                pass\n",
    "\n",
    "    # Always store distribution (top 20)\n",
    "    dist = df[col].value_counts(dropna=False).to_frame(\"count\")\n",
    "    target_info[\"distribution\"] = dist.head(20)\n",
    "\n",
    "    # Balance metrics for binary targets (from series_for_balance if set)\n",
    "    if series_for_balance is not None:\n",
    "        counts = series_for_balance.value_counts(dropna=False)\n",
    "        total = int(counts.sum())\n",
    "        pos = int(counts.get(1, 0))\n",
    "        neg = int(counts.get(0, 0))\n",
    "        minority = min(pos, neg)\n",
    "        majority = max(pos, neg)\n",
    "        minority_rate = (minority / total) if total else 0.0\n",
    "        imbalance_ratio = (majority / minority) if minority > 0 else float(\"inf\")\n",
    "        target_info[\"class_balance\"] = {\n",
    "            \"total\": total,\n",
    "            \"pos\": pos,\n",
    "            \"neg\": neg,\n",
    "            \"minority_rate\": minority_rate,\n",
    "            \"imbalance_ratio\": imbalance_ratio\n",
    "        }\n",
    "        # keep your chosen threshold; here 10%\n",
    "        if minority_rate < 0.10:\n",
    "            issues.append((\"IMBALANCE\", f\"Minority class <10% (minority_rate={minority_rate:.3f}). Consider resampling/thresholding.\"))\n",
    "\n",
    "    # Optional: if ordinal Fatality Risk was mapped, show level frequencies too\n",
    "    if OUTCOME == \"Fatality Risk\" and target_info.get(\"ordinal_column\"):\n",
    "        ord_dist = df[target_info[\"ordinal_column\"]].value_counts(dropna=False).sort_index().to_frame(\"count\")\n",
    "        target_info[\"ordinal_distribution\"] = ord_dist\n",
    "\n",
    "    # Display summary for the notebook run\n",
    "    print(f\"### Target `{col}` (k={k})\")\n",
    "    display(target_info[\"distribution\"])\n",
    "    cb = target_info.get(\"class_balance\")\n",
    "    if isinstance(cb, dict):\n",
    "        print(\"\\nClass balance (binary):\")\n",
    "        print(f\"- total={cb['total']}, pos={cb['pos']}, neg={cb['neg']}\")\n",
    "        print(f\"- minority_rate={cb['minority_rate']:.3f}, imbalance_ratio={cb['imbalance_ratio']:.2f}\")\n",
    "    if OUTCOME == \"Fatality Risk\" and target_info.get(\"ordinal_distribution\") is not None:\n",
    "        print(\"\\nOrdinal distribution (mapped):\")\n",
    "        display(target_info[\"ordinal_distribution\"])\n",
    "\n",
    "else:\n",
    "    issues.append((\"TARGET\", f\"Target `{TARGET}` not found\"))\n",
    "    print(f\"[WARN] Target `{TARGET}` not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf52e8c",
   "metadata": {},
   "source": [
    "## **7) Class Imbalance Indicator**\n",
    "Reports class counts/percentages and flags severe imbalance when the minority rate is too low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b82f205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>680584</td>\n",
       "      <td>0.7212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263160</td>\n",
       "      <td>0.2788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count     pct\n",
       "class                \n",
       "0      680584  0.7212\n",
       "1      263160  0.2788"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IMBALANCE] Binary target detected: positive='1', rate=0.279 (looks OK)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "issues = issues if 'issues' in globals() else []\n",
    "\n",
    "if TARGET and TARGET in df.columns:\n",
    "    vc = df[TARGET].value_counts(dropna=False)\n",
    "    vc_df = vc.rename_axis(\"class\").to_frame(\"count\")\n",
    "    vc_df[\"pct\"] = (vc_df[\"count\"] / len(df)).round(4)\n",
    "\n",
    "    # Show distribution once\n",
    "    try:\n",
    "        display(vc_df)\n",
    "    except Exception:\n",
    "        print(vc_df)\n",
    "\n",
    "    # Persist into target_info for final report\n",
    "    target_info = locals().get(\"target_info\", {})\n",
    "    target_info[\"name\"] = TARGET\n",
    "    target_info[\"k\"] = int(df[TARGET].nunique(dropna=True))\n",
    "    target_info[\"distribution\"] = vc_df.reset_index()\n",
    "\n",
    "    # Determine how many classes (ignoring NaN)\n",
    "    levels = [cls for cls in vc.index.tolist() if pd.notna(cls)]\n",
    "    n_classes = len(levels)\n",
    "\n",
    "    # Optional: allow a user-configured positive class label\n",
    "    POSITIVE_LABEL = locals().get(\"POSITIVE_LABEL\", None)\n",
    "\n",
    "    if n_classes == 2:\n",
    "        # Treat as binary even if labels are strings\n",
    "        if POSITIVE_LABEL in levels:\n",
    "            pos_name = POSITIVE_LABEL\n",
    "            neg_name = levels[0] if levels[1] == POSITIVE_LABEL else levels[1]\n",
    "        else:\n",
    "            # pick minority as positive by default\n",
    "            pos_name = vc.idxmin()\n",
    "            neg_name = vc.idxmax()\n",
    "\n",
    "        pos = int(vc.get(pos_name, 0))\n",
    "        neg = int(vc.get(neg_name, 0))\n",
    "        total = int(len(df))\n",
    "        pos_rate = (pos / total) if total else 0.0\n",
    "\n",
    "        # flag imbalance if extreme (<20% or >80% positive)\n",
    "        if pos_rate < 0.20 or pos_rate > 0.80:\n",
    "            issues.append((\"IMBALANCE\", f\"Target '{TARGET}' imbalanced (positive='{pos_name}', rate={pos_rate:.3f})\"))\n",
    "            print(f\"[IMBALANCE] Binary target detected: positive='{pos_name}', rate={pos_rate:.3f}\")\n",
    "        else:\n",
    "            print(f\"[IMBALANCE] Binary target detected: positive='{pos_name}', rate={pos_rate:.3f} (looks OK)\")\n",
    "\n",
    "        # store detailed balance for final report\n",
    "        minority = min(pos, neg)\n",
    "        target_info[\"class_balance\"] = {\n",
    "            \"total\": total,\n",
    "            \"pos\": pos,\n",
    "            \"neg\": neg,\n",
    "            \"pos_label\": str(pos_name),\n",
    "            \"neg_label\": str(neg_name),\n",
    "            \"minority_rate\": (minority / total) if total else 0.0,\n",
    "            \"imbalance_ratio\": (max(pos, neg) / max(1, minority)) if minority else float(\"inf\"),\n",
    "        }\n",
    "\n",
    "    elif n_classes > 2:\n",
    "        # Multi-class: just show top classes (already displayed above)\n",
    "        print(\"[IMBALANCE] Multi-class target â€” review class distribution above.\")\n",
    "    else:\n",
    "        print(\"[IMBALANCE] Target has <2 non-null classes; nothing to assess.\")\n",
    "    \n",
    "    # write back\n",
    "    locals()[\"target_info\"] = target_info\n",
    "\n",
    "else:\n",
    "    print(\"[IMBALANCE] Skipped: TARGET not set or missing from df.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd191bc",
   "metadata": {},
   "source": [
    "## **8) Boolean Normalization Audit for _i Flags**\n",
    "\n",
    "Audits all *_i indicators and warns if any use encodings outside {0,1,NaN}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b8d0e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BOOLEANS] All *_i flags are in {{0,1,NaN}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "issues = issues if 'issues' in globals() else []\n",
    "\n",
    "# Consider any column ending with \"_i\" as an indicator/boolean.\n",
    "flag_cols = [c for c in df.columns if c.endswith('_i')]\n",
    "\n",
    "bad_flags = {}\n",
    "for c in flag_cols:\n",
    "    # look only at observed, non-null values\n",
    "    uniq = set(pd.Series(df[c].dropna().unique()).tolist())\n",
    "    # allow only {0,1}; NaN is allowed separately\n",
    "    if not (uniq <= {0, 1}):\n",
    "        bad_flags[c] = sorted(list(uniq))[:12]  # sample first few values\n",
    "\n",
    "if bad_flags:\n",
    "    issues.append((\"BOOLEANS\", f\"Non-binary encodings in flags: {list(bad_flags.keys())}\"))\n",
    "    print(\"[BOOLEANS] Non {0,1} values detected in:\")\n",
    "    for k, v in bad_flags.items():\n",
    "        print(f\"  - {k}: examples -> {v}\")\n",
    "else:\n",
    "    print(\"[BOOLEANS] All *_i flags are in {{0,1,NaN}}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423fc445",
   "metadata": {},
   "source": [
    "## **9) Leakage** \n",
    "\n",
    "Surfaces name-based suspects and enforces removal of forbidden leakage/ID columns before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba05142c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suspected_leakage_cols</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crash_type_bin</td>\n",
       "      <td>hints</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  suspected_leakage_cols source\n",
       "0         crash_type_bin  hints"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LEAKAGE] No common leakage/ID/post-event columns matched.\n",
      "[LEAKAGE] No forbidden columns detected (strict list).\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "issues = issues if 'issues' in globals() else []\n",
    "\n",
    "# 0) Outcome-specific name hints \n",
    "if TARGET and TARGET in df.columns:\n",
    "    hints = [h.lower() for h in LEAKAGE_HINTS.get(OUTCOME, [])]\n",
    "    found_hint = [c for c in df.columns if any(h in c.lower() for h in hints) and c != TARGET]\n",
    "    if found_hint:\n",
    "        issues.append((\"LEAKAGE\", f\"Suspected leakage columns (name hints): {found_hint[:12]}{'...' if len(found_hint)>12 else ''}\"))\n",
    "        display(pd.DataFrame({'suspected_leakage_cols': found_hint}).assign(source=\"hints\"))\n",
    "\n",
    "# 1) Expanded common leakage/ID/post-event list (flag only)\n",
    "COMMON_LEAKAGE_EXACT = {\n",
    "    # already had some of these\n",
    "    \"report_type\", \"photos_taken_i\", \"statements_taken_i\", \"date_police_notified\",\n",
    "    \"veh_vehicle_id_list_json\", \"ppl_person_id_list_json\", \"location_json\", \"street_name\",\n",
    "    # more admin/ID/meta\n",
    "    \"rd_no\", \"report_number\", \"case_no\", \"case_number\", \"case_status\", \"case_disposition\",\n",
    "    \"investigation_status\", \"report_completed_i\",\n",
    "    \"date_reported\", \"time_reported\", \"time_police_notified\",\n",
    "    # adjudication / enforcement\n",
    "    \"citation\", \"citation_number\", \"violation_code\", \"ticket_number\", \"arrest_flag\", \"charge_code\",\n",
    "    # medical / EMS / post-crash response\n",
    "    \"ems_run_number\", \"ambulance_id\", \"hospital_name\", \"hospital_code\", \"trauma_center\",\n",
    "    # file/meta columns that shouldnâ€™t be model features\n",
    "    \"created_at\", \"updated_at\", \"loaded_at\", \"ingest_time\", \"etl_batch_id\", \"source_file\", \"row_hash\"\n",
    "}\n",
    "\n",
    "# 2) Regex patterns to catch families of leakage columns (flag only)\n",
    "COMMON_LEAKAGE_PATTERNS = [\n",
    "    # IDs & JSON aggregates\n",
    "    r\"_id_list_json$\", r\"\\b[a-z]+_id\\b\", r\"\\bveh_.*_id\\b\", r\"\\bppl_.*_id\\b\",\n",
    "    # enforcement & adjudication\n",
    "    r\"\\bcitation\", r\"\\bticket\", r\"\\bviolation\", r\"\\barrest\", r\"\\bcharge\",\n",
    "    # post-event admin times/dates\n",
    "    r\"date_.*(reported|notified)\", r\"time_.*(reported|notified)\",\n",
    "    # injuries / severity (likely label leakage for certain outcomes)\n",
    "    r\"\\binjur\", r\"incapacitating|serious|severe|fatal|death|deceased|pronounced\",\n",
    "    # tow-related (post-crash response)\n",
    "    r\"\\btow(ed|ing)?\\b\", r\"vehicle_?_?towed\", r\"num_vehicles_towed\", r\"tow_company|tow_destination\",\n",
    "    # medical/EMS\n",
    "    r\"\\bems\\b|\\bambulance\\b|\\bhosp|\\btrauma|\\ber\\b|\\bmedic\",\n",
    "    # meta/ETL\n",
    "    r\"^etl_\", r\"^ingest_\", r\"^load_\", r\"_ingested$\", r\"_loaded$\"\n",
    "]\n",
    "\n",
    "# 3) Scan columns\n",
    "cols = df.columns.tolist()\n",
    "suspects_exact = [c for c in cols if c in COMMON_LEAKAGE_EXACT]\n",
    "rx = re.compile(\"|\".join(COMMON_LEAKAGE_PATTERNS), flags=re.IGNORECASE)\n",
    "suspects_regex = [c for c in cols if rx.search(c)]\n",
    "\n",
    "# De-dup + remove true target\n",
    "suspects = sorted(set(suspects_exact) | set(suspects_regex))\n",
    "if TARGET in suspects:\n",
    "    suspects.remove(TARGET)\n",
    "\n",
    "if suspects:\n",
    "    print(\"[LEAKAGE] Common leakage/ID/post-event suspects:\")\n",
    "    display(pd.DataFrame({\"suspected_leakage_cols\": suspects}).assign(source=\"common\"))\n",
    "    issues.append((\"LEAKAGE\", f\"Common leakage/ID/post-event suspects: {suspects[:20]}{'...' if len(suspects)>20 else ''}\"))\n",
    "else:\n",
    "    print(\"[LEAKAGE] No common leakage/ID/post-event columns matched.\")\n",
    "\n",
    "# 4) Keeping â€œFORBIDDENâ€ list as a strict subset \n",
    "FORBIDDEN = {\n",
    "    \"report_type\",\"photos_taken_i\",\"statements_taken_i\",\"date_police_notified\",\n",
    "    \"veh_vehicle_id_list_json\",\"ppl_person_id_list_json\",\"location_json\",\"street_name\"\n",
    "}\n",
    "present_forbidden = [c for c in FORBIDDEN if c in df.columns and c != TARGET]\n",
    "if present_forbidden:\n",
    "    issues.append((\"LEAKAGE\", f\"Forbidden (leakage/IDs) present: {present_forbidden}\"))\n",
    "    print(\"[LEAKAGE] Forbidden present:\", present_forbidden)\n",
    "else:\n",
    "    print(\"[LEAKAGE] No forbidden columns detected (strict list).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e956e29",
   "metadata": {},
   "source": [
    "## **10) Derived Time Features Present**\n",
    "\n",
    "Verifies year, month, day_of_week, hour, is_weekend are available; shows date range and latest crash date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bffd9142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIME] All derived time columns present\n"
     ]
    }
   ],
   "source": [
    "issues = issues if 'issues' in globals() else []\n",
    "expected_time_cols = ['year','month','day_of_week','hour','is_weekend']\n",
    "missing_time = [c for c in expected_time_cols if c not in df.columns]\n",
    "if missing_time:\n",
    "    issues.append((\"TIME\", f\"Missing derived time columns: {missing_time}\"))\n",
    "    print(\"[TIME] Missing:\", missing_time)\n",
    "else:\n",
    "    print(\"[TIME] All derived time columns present\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7cf559",
   "metadata": {},
   "source": [
    "## **11) Geo Bins & grid_id Consistency**\n",
    "\n",
    "Checks that grid_id numerically matches lat_bin/lng_bin (ignoring formatting) and reports any mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77ea413f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GEO] Missing: ['lat_bin', 'lng_bin', 'grid_id']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "issues = issues if 'issues' in globals() else []\n",
    "expected_geo = ['lat_bin','lng_bin','grid_id']\n",
    "missing_geo = [c for c in expected_geo if c not in df.columns]\n",
    "if missing_geo:\n",
    "    issues.append((\"GEO\", f\"Missing geo bin columns: {missing_geo}\"))\n",
    "    print(\"[GEO] Missing:\", missing_geo)\n",
    "else:\n",
    "    derived = df['lat_bin'].astype(str).str.strip() + \"_\" + df['lng_bin'].astype(str).str.strip()\n",
    "    mismatch = (df['grid_id'].astype(str).str.strip() != derived).sum()\n",
    "    if mismatch > 0:\n",
    "            print(\"[GEO] grid_id matches lat/lng bins\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b4337",
   "metadata": {},
   "source": [
    "## **12) Categorical cardinality & Outliers**\n",
    "\n",
    "Flags high-cardinality categoricals to compress and runs an IQR-based scan for numeric outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31fa5b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>unique_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crash_record_id</td>\n",
       "      <td>943744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prim_contributory_cause</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sec_contributory_cause</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>traffic_control_device</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weather_condition</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day_of_week</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lighting_condition</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>roadway_surface_cond</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hour_bin</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    column  unique_values\n",
       "0          crash_record_id         943744\n",
       "3  prim_contributory_cause             40\n",
       "6   sec_contributory_cause             40\n",
       "4   traffic_control_device             17\n",
       "1        weather_condition             10\n",
       "7              day_of_week              7\n",
       "2       lighting_condition              5\n",
       "5     roadway_surface_cond              5\n",
       "8                 hour_bin              4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>outlier_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crash_type</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>year</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>month</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>day</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hour</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is_weekend</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hit_and_run_i</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>crash_type_bin</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           column  outlier_rate\n",
       "0      crash_type           0.0\n",
       "1            year           0.0\n",
       "2           month           0.0\n",
       "3             day           0.0\n",
       "4            hour           0.0\n",
       "5      is_weekend           0.0\n",
       "6   hit_and_run_i           0.0\n",
       "7  crash_type_bin           0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OUTLIERS_DOMAIN] All domain caps satisfied\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Categorical\n",
    "cat_cols = [c for c in df.columns if df[c].dtype == 'object']\n",
    "cat_card = pd.DataFrame({'column': cat_cols, 'unique_values': [df[c].nunique(dropna=True) for c in cat_cols]}).sort_values('unique_values', ascending=False)\n",
    "display(cat_card.head(20))\n",
    "if (cat_card['unique_values'] > HIGH_CARD_LIMIT).any():\n",
    "    issues.append((\"CARDINALITY\", \"High-cardinality categoricals present\"))\n",
    "\n",
    "# Outliers (IQR)\n",
    "num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "out_rows = []\n",
    "for c in num_cols:\n",
    "    s = df[c].dropna()\n",
    "    if s.empty: \n",
    "        continue\n",
    "    q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    if not pd.isna(iqr) and iqr != 0:\n",
    "        lo, hi = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "        rate = ((df[c] < lo) | (df[c] > hi)).mean()\n",
    "        rate = float(rate) if not pd.isna(rate) else 0.0\n",
    "        out_rows.append((c, rate))\n",
    "out_df = pd.DataFrame(out_rows, columns=['column','outlier_rate']).sort_values('outlier_rate', ascending=False)\n",
    "display(out_df.head(20))\n",
    "if (out_df['outlier_rate'] > OUTLIER_RATE_WARN).any():\n",
    "    issues.append((\"OUTLIERS\", \"Some numeric columns exceed outlier threshold\"))\n",
    "issues = issues if 'issues' in globals() else []\n",
    "violations = []\n",
    "\n",
    "def _max_over(col, k):\n",
    "    if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):\n",
    "        mx = pd.to_numeric(df[col], errors='coerce').max()\n",
    "        if pd.notna(mx) and mx > k:\n",
    "            violations.append((col, float(mx), k))\n",
    "\n",
    "CAPS = {'veh_count': 5, 'ppl_count': 10, 'injuries_total': 20}\n",
    "for col, cap in CAPS.items():\n",
    "    _max_over(col, cap)\n",
    "\n",
    "age_cols = [c for c in df.columns if 'age' in c and pd.api.types.is_numeric_dtype(df[c])]\n",
    "for c in age_cols:\n",
    "    mx = pd.to_numeric(df[c], errors='coerce').max()\n",
    "    if pd.notna(mx) and mx > 110:\n",
    "        violations.append((c, float(mx), 110))\n",
    "\n",
    "if violations:\n",
    "    issues.append((\"OUTLIERS_DOMAIN\", f\"Domain caps exceeded: {violations[:10]}\"))\n",
    "    print(\"[OUTLIERS_DOMAIN] Exceeded caps:\", violations[:10])\n",
    "else:\n",
    "    print(\"[OUTLIERS_DOMAIN] All domain caps satisfied\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ee99a4",
   "metadata": {},
   "source": [
    "## **13) Gold Non-Redundancy (Table-Level Duplicate Check)**\n",
    "\n",
    "Queries DuckDB to confirm no duplicate crash_record_id are present in the Gold table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "baaa298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GOLD] OK: Unique crash_record_id enforced in gold\".\"crash_gold\".\"crashes\n"
     ]
    }
   ],
   "source": [
    "issues = issues if 'issues' in globals() else []\n",
    "try:\n",
    "    DB_PATH  # noqa\n",
    "    TABLE_NAME  # noqa\n",
    "except NameError:\n",
    "    print(\"[GOLD] Skipped: DB_PATH or TABLE_NAME is not defined in this notebook.\")\n",
    "else:\n",
    "    try:\n",
    "        import duckdb\n",
    "        with duckdb.connect(DB_PATH, read_only=True) as con:\n",
    "            total_rows = con.execute(f'SELECT COUNT(*) FROM \"{TABLE_NAME}\"').fetchone()[0]\n",
    "            distinct_ids = con.execute(f'SELECT COUNT(DISTINCT crash_record_id) FROM \"{TABLE_NAME}\"').fetchone()[0]\n",
    "        if total_rows != distinct_ids:\n",
    "            issues.append((\"GOLD_DUPES\", f'Gold table \"{TABLE_NAME}\" has duplicate crash_record_id rows '\n",
    "                                         f'(total={total_rows}, distinct={distinct_ids})'))\n",
    "            print(f'[GOLD] WARNING: total_rows={total_rows}, distinct_ids={distinct_ids}')\n",
    "        else:\n",
    "            print(f'[GOLD] OK: Unique crash_record_id enforced in {TABLE_NAME}')\n",
    "    except Exception as e:\n",
    "        issues.append((\"GOLD_CHECK_ERROR\", f\"Error while checking Gold table: {e!r}\"))\n",
    "        print(\"[GOLD] Error:\", repr(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3882bc4b",
   "metadata": {},
   "source": [
    "## **14) Final findings**\n",
    "\n",
    "Generates a concise narrative QC report summarizing findings and prioritized next actions for modeling readiness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e98bcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# QC Summary â€” 2025-10-23 11:15\n",
      "\n",
      "## Dataset\n",
      "Rows Ã— Cols: 943,744 Ã— 19\n",
      "ID column: crash_record_id\n",
      "Date column: crash_date\n",
      "Outcome: Crash_type  |  Target: crash_type\n",
      "Latest crash date: 2025-10-16 01:10:00\n",
      "## Target Analysis\n",
      "Target column `crash_type` with 2 distinct non-null values\n",
      "Example values: [0, 1]\n",
      "\n",
      "Top of target distribution:\n",
      "   class   count     pct\n",
      "0      0  680584  0.7212\n",
      "1      1  263160  0.2788\n",
      "\n",
      "Class balance (binary):\n",
      "- total=943744, pos=263160, neg=680584\n",
      "- minority_rate=0.279, imbalance_ratio=2.5861985104119167\n",
      "\n",
      "## Schema & Primary Key\n",
      "Required columns present and primary key looks valid.\n",
      "\n",
      "## Boolean Flags (*_i)\n",
      "All *_i flags appear to be normalized to {0,1,NaN} or no *_i flags found.\n",
      "\n",
      "## Duplicates\n",
      "No duplicate issues detected.\n",
      "\n",
      "## Missingness\n",
      "Top 10 columns by missing rate:\n",
      "                 column missing_rate\n",
      "   roadway_surface_cond         5.9%\n",
      " traffic_control_device         3.9%\n",
      "      weather_condition         2.1%\n",
      "     lighting_condition         1.4%\n",
      "             crash_date         0.0%\n",
      "        crash_record_id         0.0%\n",
      "prim_contributory_cause         0.0%\n",
      "             crash_type         0.0%\n",
      " sec_contributory_cause         0.0%\n",
      "                   year         0.0%\n",
      "\n",
      "## Categorical Cardinality\n",
      "No high-cardinality categorical columns flagged.\n",
      "\n",
      "## Numeric Outliers (IQR)\n",
      "No numeric columns exceeded the outlier threshold.\n",
      "\n",
      "## Domain Caps\n",
      "All domain cap checks passed (veh_count, ppl_count, injuries_total, age bounds).\n",
      "\n",
      "## Date & Geo\n",
      "No date column parsed or not available.\n",
      "No lat/lon bounds check or columns not present.\n",
      "\n",
      "## Leakage\n",
      "No suspected leakage columns by name heuristic.\n",
      "- Suspected leakage columns (name hints): ['crash_type_bin']\n",
      "\n",
      "## Strong Numeric Correlations (|r| â‰¥ 0.7)\n",
      "None detected above threshold or skipped in this QC.\n",
      "\n",
      "## Gold Layer\n",
      "Gold table check: no duplicate crash_record_id detected (or check skipped).\n",
      "\n",
      "## Recommended Next Actions\n",
      "- Drop or justify suspected leakage columns; ensure only report-time features remain.\n",
      "- Ensure lat_bin/lng_bin exist and grid_id = f(lat_bin,lng_bin).\n",
      "- Reduce high-cardinality categoricals (group rare levels, hashing, or target encoding).\n",
      "\n",
      "â€” End of QC Report â€”\n"
     ]
    }
   ],
   "source": [
    "# === Final Narrative QC Report  ===\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def _pct(x):\n",
    "    try:\n",
    "        return f\"{100*x:.1f}%\"\n",
    "    except Exception:\n",
    "        return \"-\"\n",
    "\n",
    "# Safely grab prior-cell variables (with defaults)\n",
    "issues      = locals().get(\"issues\", [])\n",
    "df          = locals().get(\"df\")\n",
    "ID          = locals().get(\"ID\", None)\n",
    "DATE        = locals().get(\"DATE\", None)\n",
    "OUTCOME     = locals().get(\"OUTCOME\", \"<unset>\")\n",
    "TARGET      = locals().get(\"TARGET\", \"<unset>\")\n",
    "miss        = locals().get(\"miss\", pd.DataFrame(columns=[\"column\",\"missing_rate\"]))\n",
    "hi_card     = locals().get(\"hi_card\", pd.DataFrame(columns=[\"column\",\"unique_values\"]))\n",
    "flag_out    = locals().get(\"flag_out\", pd.DataFrame(columns=[\"column\",\"outlier_rate\"]))\n",
    "corr_pairs  = locals().get(\"corr_pairs\", pd.DataFrame(columns=[\"col_a\",\"col_b\",\"pearson_r\"]))\n",
    "leak_cols   = locals().get(\"leak_cols\", [])\n",
    "date_range  = locals().get(\"date_range\", None)      # (min_ts, max_ts)\n",
    "geo_stats   = locals().get(\"geo_stats\", None)       # {\"lat_ok\": float, \"lon_ok\": float}\n",
    "target_info = locals().get(\"target_info\", {})       # {\"name\",\"k\",\"values\",\"interpretation\",\"distribution\",\"class_balance\"}\n",
    "dup_preview = locals().get(\"dup_preview\", None)     # sample duplicate IDs\n",
    "\n",
    "print(f\"# QC Summary â€” {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\")\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset\n",
    "# ---------------------------\n",
    "print(\"## Dataset\")\n",
    "if df is None:\n",
    "    raise RuntimeError(\"`df` was not found. Run earlier cells first.\")\n",
    "print(f\"Rows Ã— Cols: {df.shape[0]:,} Ã— {df.shape[1]}\")\n",
    "print(f\"ID column: {ID if (isinstance(ID, str) and ID in df.columns) else 'â€”'}\")\n",
    "print(f\"Date column: {DATE if (isinstance(DATE, str) and DATE in df.columns) else 'â€”'}\")\n",
    "print(f\"Outcome: {OUTCOME}  |  Target: {TARGET}\")\n",
    "latest_crash_date = None\n",
    "if isinstance(DATE, str) and (df is not None) and (DATE in df.columns):\n",
    "    _dt = pd.to_datetime(df[DATE], errors=\"coerce\")\n",
    "    if _dt.notna().any():\n",
    "        latest_crash_date = _dt.max()\n",
    "print(f\"Latest crash date:\", latest_crash_date)\n",
    "\n",
    "# ---------------------------\n",
    "# Target Analysis\n",
    "# ---------------------------\n",
    "print(\"## Target Analysis\")\n",
    "if target_info.get(\"name\"):\n",
    "    print(f\"Target column `{target_info['name']}` with {target_info.get('k','?')} distinct non-null values\")\n",
    "    if target_info.get(\"interpretation\"):\n",
    "        print(f\"Interpreted as: {target_info['interpretation']}\")\n",
    "    if target_info.get(\"values\"):\n",
    "        print(\"Example values:\", target_info[\"values\"])\n",
    "    if isinstance(target_info.get(\"distribution\"), pd.DataFrame):\n",
    "        print(\"\\nTop of target distribution:\")\n",
    "        print(target_info[\"distribution\"].to_string())\n",
    "    cb = target_info.get(\"class_balance\")\n",
    "    if isinstance(cb, dict):\n",
    "        print(\"\\nClass balance (binary):\")\n",
    "        print(f\"- total={cb.get('total','?')}, pos={cb.get('pos','?')}, neg={cb.get('neg','?')}\")\n",
    "        if \"minority_rate\" in cb:\n",
    "            print(f\"- minority_rate={cb['minority_rate']:.3f}, imbalance_ratio={cb.get('imbalance_ratio','?')}\")\n",
    "else:\n",
    "    print(\"Target not found or not analyzed in prior cells.\")\n",
    "print()\n",
    "\n",
    "# ---------------------------\n",
    "# Schema & Primary Key\n",
    "# ---------------------------\n",
    "print(\"## Schema & Primary Key\")\n",
    "schema_msgs = [m for (t,m) in issues if t in {\"SCHEMA\",\"KEY\"}]\n",
    "if schema_msgs:\n",
    "    for m in schema_msgs:\n",
    "        print(\"-\", m)\n",
    "else:\n",
    "    print(\"Required columns present and primary key looks valid.\")\n",
    "print()\n",
    "\n",
    "# ---------------------------\n",
    "# Boolean Flags (*_i)\n",
    "# ---------------------------\n",
    "print(\"## Boolean Flags (*_i)\")\n",
    "bool_msgs = [m for (t,m) in issues if t == \"BOOLEANS\"]\n",
    "if bool_msgs:\n",
    "    for m in bool_msgs:\n",
    "        print(\"-\", m)\n",
    "else:\n",
    "    print(\"All *_i flags appear to be normalized to {0,1,NaN} or no *_i flags found.\")\n",
    "print()\n",
    "\n",
    "# ---------------------------\n",
    "# Duplicates\n",
    "# ---------------------------\n",
    "print(\"## Duplicates\")\n",
    "dup_msgs = [m for (t,m) in issues if t == \"DUPLICATES\"]\n",
    "if dup_msgs:\n",
    "    for m in dup_msgs:\n",
    "        print(\"-\", m)\n",
    "    if dup_preview is not None:\n",
    "        print(\"\\nSample duplicate IDs:\")\n",
    "        print(dup_preview.to_string())\n",
    "else:\n",
    "    print(\"No duplicate issues detected.\")\n",
    "print()\n",
    "\n",
    "# ---------------------------\n",
    "# Missingness\n",
    "# ---------------------------\n",
    "print(\"## Missingness\")\n",
    "if not miss.empty:\n",
    "    top_miss = miss.head(10).copy()\n",
    "    top_miss[\"missing_rate\"] = (top_miss[\"missing_rate\"]*100).round(1).astype(str) + \"%\"\n",
    "    print(\"Top 10 columns by missing rate:\")\n",
    "    print(top_miss.to_string(index=False))\n",
    "else:\n",
    "    print(\"No missingness table available.\")\n",
    "print()\n",
    "\n",
    "# ---------------------------\n",
    "# Categorical Cardinality\n",
    "# ---------------------------\n",
    "print(\"## Categorical Cardinality\")\n",
    "if not hi_card.empty:\n",
    "    print(f\"{hi_card.shape[0]} categorical columns exceed the high-cardinality threshold.\")\n",
    "    print(\"Top offenders:\")\n",
    "    print(hi_card.head(10).to_string(index=False))\n",
    "else:\n",
    "    print(\"No high-cardinality categorical columns flagged.\")\n",
    "print()\n",
    "\n",
    "# ---------------------------\n",
    "# Numeric Outliers (IQR)\n",
    "# ---------------------------\n",
    "print(\"## Numeric Outliers (IQR)\")\n",
    "if not flag_out.empty:\n",
    "    show = flag_out.head(10).copy()\n",
    "    show[\"outlier_rate\"] = (show[\"outlier_rate\"]*100).round(1).astype(str) + \"%\"\n",
    "    print(f\"{flag_out.shape[0]} numeric columns exceed the outlier threshold.\")\n",
    "    print(show.to_string(index=False))\n",
    "else:\n",
    "    print(\"No numeric columns exceeded the outlier threshold.\")\n",
    "print()\n",
    "\n",
    "# ---------------------------\n",
    "# Domain Caps (veh/ppl/injuries/age)\n",
    "# ---------------------------\n",
    "print(\"## Domain Caps\")\n",
    "dom_msgs = [m for (t,m) in issues if t == \"OUTLIERS_DOMAIN\"]\n",
    "if dom_msgs:\n",
    "    for m in dom_msgs:\n",
    "        print(\"-\", m)\n",
    "else:\n",
    "    print(\"All domain cap checks passed (veh_count, ppl_count, injuries_total, age bounds).\")\n",
    "print()\n",
    "\n",
    "# ---------------------------\n",
    "# Date & Geo\n",
    "# ---------------------------\n",
    "print(\"## Date & Geo\")\n",
    "if isinstance(date_range, tuple) and len(date_range) == 2:\n",
    "    print(\"Date range:\", date_range[0], \"â†’\", date_range[1])\n",
    "else:\n",
    "    print(\"No date column parsed or not available.\")\n",
    "if isinstance(geo_stats, dict) and {\"lat_ok\",\"lon_ok\"} <= geo_stats.keys():\n",
    "    print(f\"Geo bounds OK fraction â€” lat: {_pct(geo_stats['lat_ok'])}, lon: {_pct(geo_stats['lon_ok'])}\")\n",
    "else:\n",
    "    print(\"No lat/lon bounds check or columns not present.\")\n",
    "time_msgs = [m for (t,m) in issues if t == \"TIME\"]\n",
    "if time_msgs:\n",
    "    for m in time_msgs:\n",
    "        print(\"-\", m)\n",
    "print()\n",
    "\n",
    "# ---------------------------\n",
    "# Leakage\n",
    "# ---------------------------\n",
    "print(\"## Leakage\")\n",
    "if leak_cols:\n",
    "    print(\"Suspected (name-based) leakage columns:\")\n",
    "    print(pd.DataFrame({\"suspected_leakage_cols\": leak_cols}).head(20).to_string(index=False))\n",
    "else:\n",
    "    print(\"No suspected leakage columns by name heuristic.\")\n",
    "leak_enforce = [m for (t,m) in issues if t == \"LEAKAGE\"]\n",
    "if leak_enforce:\n",
    "    for m in leak_enforce:\n",
    "        print(\"-\", m)\n",
    "print()\n",
    "\n",
    "# ---------------------------\n",
    "# Strong Numeric Correlations\n",
    "# ---------------------------\n",
    "# This section only prints if corr_pairs exists and is non-empty.\n",
    "print(\"## Strong Numeric Correlations (|r| â‰¥ 0.7)\")\n",
    "if isinstance(corr_pairs, pd.DataFrame) and not corr_pairs.empty:\n",
    "    print(corr_pairs.head(20).to_string(index=False))\n",
    "else:\n",
    "    print(\"None detected above threshold or skipped in this QC.\")\n",
    "print()\n",
    "\n",
    "# ---------------------------\n",
    "# Gold Layer (Non-Redundancy)\n",
    "# ---------------------------\n",
    "print(\"## Gold Layer\")\n",
    "gold_msgs = [m for (t,m) in issues if t in {\"GOLD_DUPES\",\"GOLD_CHECK_ERROR\"}]\n",
    "if gold_msgs:\n",
    "    for m in gold_msgs:\n",
    "        print(\"-\", m)\n",
    "else:\n",
    "    print(\"Gold table check: no duplicate crash_record_id detected (or check skipped).\")\n",
    "print()\n",
    "\n",
    "# ---------------------------\n",
    "# Recommended Next Actions\n",
    "# ---------------------------\n",
    "print(\"## Recommended Next Actions\")\n",
    "recommendations = []\n",
    "for tag, msg in issues:\n",
    "    t = tag.upper()\n",
    "    m = msg.lower()\n",
    "    if t == \"TARGET\" and (\"binary\" in m or \"0/1\" in m or \"encode\" in m):\n",
    "        recommendations.append(\"Map the target to {0,1} and document the mapping used.\")\n",
    "    if t == \"MISSINGNESS\":\n",
    "        recommendations.append(\"Impute or drop columns with high missingness; document choices and thresholds.\")\n",
    "    if t == \"CARDINALITY\":\n",
    "        recommendations.append(\"Reduce high-cardinality categoricals (group rare levels, hashing, or target encoding).\")\n",
    "    if t == \"OUTLIERS\":\n",
    "        recommendations.append(\"Winsorize/clip, transform, or validate data entry for flagged numeric columns.\")\n",
    "    if t == \"OUTLIERS_DOMAIN\":\n",
    "        recommendations.append(\"Enforce domain caps (veh/ppl/injuries/age) or justify exceptions with domain notes.\")\n",
    "    if t == \"DUPLICATES\":\n",
    "        recommendations.append(\"Resolve duplicates with a consistent rule (latest-wins/aggregate) and de-dup the dataset.\")\n",
    "    if t == \"LEAKAGE\":\n",
    "        recommendations.append(\"Drop or justify suspected leakage columns; ensure only report-time features remain.\")\n",
    "    if t == \"BOOLEANS\":\n",
    "        recommendations.append(\"Normalize *_i flags to {0,1} and re-run QC to confirm.\")\n",
    "    if t == \"TIME\":\n",
    "        recommendations.append(\"Add derived time fields (year, month, day_of_week, hour, is_weekend).\")\n",
    "    if t == \"GEO\":\n",
    "        recommendations.append(\"Ensure lat_bin/lng_bin exist and grid_id = f(lat_bin,lng_bin).\")\n",
    "    if t == \"IMBALANCE\":\n",
    "        recommendations.append(\"Handle class imbalance (class weights, resampling, threshold tuning, or focal loss).\")\n",
    "    if t in {\"SCHEMA\",\"KEY\"}:\n",
    "        recommendations.append(\"Satisfy required schema and enforce a unique, non-null primary key.\")\n",
    "\n",
    "if not recommendations:\n",
    "    print(\"- Dataset passes current thresholds; proceed to feature engineering.\")\n",
    "else:\n",
    "    seen = set()\n",
    "    for r in recommendations:\n",
    "        if r not in seen:\n",
    "            seen.add(r)\n",
    "            print(\"-\", r)\n",
    "\n",
    "print(\"\\nâ€” End of QC Report â€”\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f8455d",
   "metadata": {},
   "source": [
    "## **ðŸ“˜ Assignment: Convert Your QC Summary into a Professional Data Quality Report**\n",
    "\n",
    "**Goal.** Using the QC summary you just generated, write a **Professional Data Quality Report** for your chosen outcome. \n",
    "\n",
    "\n",
    "### **ðŸ“¦ Deliverables**\n",
    "- **Report (PDF)**\n",
    "\n",
    "\n",
    "### **ðŸ§­ Required Structure (1-2 pages main report)**\n",
    "1) **Executive Summary**  \n",
    "   - One-paragraph verdict on overall data readiness for ML.  \n",
    "\n",
    "2) **Dataset & Target Overview**  \n",
    "   - Rows Ã— columns, ID column, Date column, **Outcome** and **Target** (state the exact column name).  \n",
    "   - Briefly characterize the target (binary/multiclass; class balance: minority %, imbalance ratio).\n",
    "\n",
    "3) **Quality Assessment (evidence-based)**  \n",
    "   Summarize the QC sections **as claims + evidence** (You can cite metrics from your QC output):  \n",
    "   - **Schema & Primary Key:** required fields present? PK unique & non-null?  \n",
    "   - **Missingness:** top missing columns (with %), plan to impute/drop.  \n",
    "   - **Categorical Cardinality:** any high-card columns and your plan to reduce them.  \n",
    "   - **Numeric Outliers (IQR) & Domain Caps:** which columns exceeded caps; justify clips vs. investigation.  \n",
    "   - **Time & Geo:** date range, latest crash date, derived time fields present, consistent with bins.  \n",
    "   - **Leakage:** confirm forbidden columns removed; mention any name-based suspects and actions.  \n",
    "   - **Gold Non-Redundancy:** duplicate key status for the Gold table.\n",
    "\n",
    "4) **Risks & Ethics (2â€“4 bullets)**  \n",
    "   - Potential biases (e.g., missingness patterns by location/time) and impact on model fairness.  \n",
    "   - Consequences of leakage or mis-specified grain.\n",
    "\n",
    "5) **Recommendations & Next Actions**  \n",
    "   - State **go/no-go for modeling** and what must be done before training.\n",
    "\n",
    "\n",
    "### **ðŸ§° Submission Notes**\n",
    "- Keep the main report **1-2 pages**.  \n",
    "- Use consistent notation, and labeled figures/tables.  \n",
    "- If you re-ran QC after fixes, **state what changed**.\n",
    "\n",
    "> **Reminder:** Your report must be **self-contained**. A reviewer should understand the datasetâ€™s fitness for modeling without opening the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "616c5812-6104-4d9d-b9a7-166c3c951a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [name]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "con = duckdb.connect(\"gold.duckdb\")\n",
    "print(con.sql(\"SHOW TABLES\").df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f02a29f-8688-4862-9480-ae608e22ce34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
